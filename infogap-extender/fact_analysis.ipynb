{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98536273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: en_Denys_Shmyhal.txt and ru_Шмыгаль,_Денис_Анатольевич.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: en_Maria_Lvova-Belova.txt and ru_Львова-Белова,_Мария_Алексеевна.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: en_Olha_Stefanishyna.txt and ru_Стефанишина,_Ольга_Витальевна.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: en_Sergey_Lavrov.txt and ru_Лавров,_Сергей_Викторович.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: en_Vladimir_Putin.txt and ru_Путин,_Владимир_Владимирович.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: en_Volodymyr_Zelenskyy.txt and ru_Зеленский,_Владимир_Александрович.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import tqdm\n",
    "import re\n",
    "\n",
    "# Read the facts.json file\n",
    "with open('output/facts.json', 'r', encoding='utf-8') as f:\n",
    "    facts = json.load(f)\n",
    "\n",
    "filenames = [\n",
    "    (\"en_Denys_Shmyhal.txt\", \"ru_Шмыгаль,_Денис_Анатольевич.txt\"),\n",
    "    (\"en_Maria_Lvova-Belova.txt\", \"ru_Львова-Белова,_Мария_Алексеевна.txt\"),\n",
    "    (\"en_Olha_Stefanishyna.txt\", \"ru_Стефанишина,_Ольга_Витальевна.txt\"),\n",
    "    (\"en_Sergey_Lavrov.txt\", \"ru_Лавров,_Сергей_Викторович.txt\"),\n",
    "    (\"en_Vladimir_Putin.txt\", \"ru_Путин,_Владимир_Владимирович.txt\"),\n",
    "    (\"en_Volodymyr_Zelenskyy.txt\", \"ru_Зеленский,_Владимир_Александрович.txt\")\n",
    "]\n",
    "\n",
    "def analyse_en_fact(en_fact, ru_facts, ollama_url=\"http://localhost:11434/api/generate\"):\n",
    "    en_prompt = f\"\"\"\n",
    "    Consider the English fact: {en_fact} Is this fact fully inferrable from the following Russian facts?\\n {ru_facts}. Return either ONLY 'yes' or ONLY 'no'.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:1b\",\n",
    "        \"prompt\": en_prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(ollama_url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"response\", \"\")\n",
    "\n",
    "def analyse_ru_fact(ru_fact, en_facts, ollama_url=\"http://localhost:11434/api/generate\"):\n",
    "    ru_prompt = f\"\"\"\n",
    "    Рассмотрим следующий факт на русском языке: {ru_fact} Можно ли этот факт полностью вывести из следующих фактов на английском языке?\\n {en_facts}. Отвечайте только «да» или только «нет».\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:1b\",\n",
    "        \"prompt\": ru_prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(ollama_url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"response\", \"\")\n",
    "\n",
    "def classify_fact(fact, language, ollama_url=\"http://localhost:11434/api/generate\"):\n",
    "    en_prompt = f\"\"\"\n",
    "    Consider the English fact: {fact}. Does this fact imply a positive or negative sentiment towards this person? Or is it simply stating a fact (neutral)? Explain in one sentence.\\n Write your response in JSON format with two keys: label (pos/neutral/neg) and explanation.\n",
    "    \"\"\"\n",
    "    ru_prompt = f\"\"\"\n",
    "    Рассмотрим английский факт: {fact}. Подразумевает ли этот факт положительное или отрицательное отношение к этому человеку? Или он просто констатирует факт (neutral)? Объясните одним предложением.\\n Напишите свой ответ в формате JSON с двумя ключами: label (pos/neutral/neg) и explanation.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:1b\",\n",
    "        \"prompt\": en_prompt if language == 'en' else ru_prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(ollama_url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"response\", \"\")\n",
    "\n",
    "def parse_response(response):\n",
    "\n",
    "    # Remove triple backticks and optional 'json' after them\n",
    "    cleaned = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", response.strip(), flags=re.IGNORECASE)\n",
    "    try:\n",
    "        data = json.loads(cleaned)\n",
    "        return data.get(\"label\", \"\").strip(), data.get(\"explanation\", \"\").strip()\n",
    "    except Exception:\n",
    "        return \"\", \"\"\n",
    "\n",
    "all_results = [] \n",
    "for en_file, ru_file in filenames:\n",
    "    print(f\"Processing files: {en_file} and {ru_file}\")\n",
    "    en_facts = next((item['facts'] for item in facts if item['filename'] == en_file), [])\n",
    "    ru_facts = next((item['facts'] for item in facts if item['filename'] == ru_file), [])\n",
    "    results = {\n",
    "        \"en_file\": en_file,\n",
    "        \"ru_file\": ru_file,\n",
    "        \"en_to_ru\": [],\n",
    "        \"ru_to_en\": [],\n",
    "    }\n",
    "\n",
    "    # EN→RU analysis\n",
    "    for en_fact in tqdm.tqdm(en_facts, desc=f\"EN→RU: {en_file}\", leave=False):\n",
    "        result = analyse_en_fact(en_fact, ru_facts).strip()\n",
    "        sentiment = parse_response(classify_fact(en_fact, 'en'))\n",
    "        results[\"en_to_ru\"].append({\"en_fact\": en_fact, \"result\": result, \"sentiment\": sentiment[0], \"explanation\": sentiment[1]})\n",
    "\n",
    "    # RU→EN analysis\n",
    "    for ru_fact in tqdm.tqdm(ru_facts, desc=f\"RU→EN: {ru_file}\", leave=False):\n",
    "        result = analyse_ru_fact(ru_fact, en_facts).strip()\n",
    "        sentiment = parse_response(classify_fact(ru_fact, 'ru'))\n",
    "        results[\"ru_to_en\"].append({\"ru_fact\": ru_fact, \"result\": result, \"sentiment\": sentiment[0], \"explanation\": sentiment[1]}) \n",
    "        # TODO MAYBE try a run with english prompt for russian facts, then we can interpret the sentiment better with explanation\n",
    "\n",
    "    all_results.append(results)\n",
    "\n",
    "with open('output/analysis_results.json', 'w', encoding='utf-8') as out_f:\n",
    "    json.dump(all_results, out_f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infogap-extender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
